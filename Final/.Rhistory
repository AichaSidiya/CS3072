labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
# ggplot(hate_crime_us_state) +
# geom_sf(aes(fill = hate_crimes_per_100k_splc)) +
# scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
# labs(title = "Hate Crimes per 100K",
# fill = "Hate Crimes per 100K") +
# theme_bw()
# ggplot(fl_votes) +
#   geom_sf(aes(fill = prop_rep20),) +
#   scale_fill_gradient(low = "#0015BC", high = "#DE0100") +
#   labs(title = "Election 2020 Results",
#        fill = "Republican shaer of votes") +
#   theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = share_non_white),) +
scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
#Read the dataset for part 1
bikeshare_day <- read.csv("data/bikeshare-day.csv")
hate_crimes <- read.csv("data/hate_crimes.csv")
us_states <- st_read("data/States_shapefile.shp")
# us_states %>%
#   slice(1:6)
us_states <- us_states %>%
rename("state" = "State_Name")
us_states <- us_states %>%
mutate(state = tolower(state))
hate_crimes <- hate_crimes %>%
mutate(state = tolower(state))
hate_crime_us_state <- left_join(hate_crimes,us_states,by="state")
# ggplot(hate_crime_us_state) +
# geom_sf(aes(fill = hate_crimes_per_100k_splc)) +
# scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
# labs(title = "Hate Crimes per 100K",
# fill = "Hate Crimes per 100K") +
# theme_bw()
# ggplot(fl_votes) +
#   geom_sf(aes(fill = prop_rep20),) +
#   scale_fill_gradient(low = "#0015BC", high = "#DE0100") +
#   labs(title = "Election 2020 Results",
#        fill = "Republican shaer of votes") +
#   theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = share_non_white),) +
scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
# ggplot(hate_crime_us_state) +
# geom_sf(aes(fill = hate_crimes_per_100k_splc)) +
# scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
# labs(title = "Hate Crimes per 100K",
# fill = "Hate Crimes per 100K") +
# theme_bw()
# ggplot(fl_votes) +
#   geom_sf(aes(fill = prop_rep20),) +
#   scale_fill_gradient(low = "#0015BC", high = "#DE0100") +
#   labs(title = "Election 2020 Results",
#        fill = "Republican shaer of votes") +
#   theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = share_non_white),)
#Read the dataset for part 1
bikeshare_day <- read.csv("data/bikeshare-day.csv")
hate_crimes <- read.csv("data/hate_crimes.csv")
us_states <- st_read("data/States_shapefile.shp")
us_states %>%
slice(1:6)
us_states <- us_states %>%
rename("state" = "State_Name")
us_states <- us_states %>%
mutate(state = tolower(state))
hate_crimes <- hate_crimes %>%
mutate(state = tolower(state))
hate_crime_us_state <- left_join(hate_crimes,us_states,by="state")
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = hate_crimes_per_100k_splc)) +
scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
#Load the required packages
library(tidyverse)
library(sf)
# library(ggplot2)
# library(caret)
# library(dplyr)
# library(readr)
# library(skimr)
#Read the dataset for part 1
bikeshare_day <- read.csv("data/bikeshare-day.csv")
hate_crimes <- read.csv("data/hate_crimes.csv")
us_states <- st_read("data/States_shapefile.shp")
us_states %>%
slice(1:6)
us_states <- us_states %>%
rename("state" = "State_Name")
us_states <- us_states %>%
mutate(state = tolower(state))
hate_crimes <- hate_crimes %>%
mutate(state = tolower(state))
hate_crime_us_state <- left_join(hate_crimes,us_states,by="state")
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = hate_crimes_per_100k_splc)) +
scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = hate_crimes_per_100k_splc),) +
scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
#Read the dataset for part 1
bikeshare_day <- read.csv("data/bikeshare-day.csv")
hate_crimes <- read.csv("data/hate_crimes.csv")
us_states <- st_read("data/States_shapefile.shp", quiet = TRUE)
us_states %>%
slice(1:6)
us_states <- us_states %>%
rename("state" = "State_Name")
us_states <- us_states %>%
mutate(state = tolower(state))
hate_crimes <- hate_crimes %>%
mutate(state = tolower(state))
hate_crime_us_state <- left_join(hate_crimes,us_states,by="state")
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = hate_crimes_per_100k_splc),) +
scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = hate_crimes_per_100k_splc, geometry = geometry) +
scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
ggplot(hate_crime_us_state) +
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = hate_crimes_per_100k_splc, geometry = geometry)) +
scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = share_non_white, geometry = geometry))+
scale_fill_gradient(low = "#FFA07A", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = hate_crimes_per_100k_splc, geometry = geometry)) +
scale_fill_gradient(low = "#FFDAB9", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = share_non_white, geometry = geometry))+
scale_fill_gradient(low = "#FFDAB9", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = hate_crimes_per_100k_splc, geometry = geometry)) +
scale_fill_gradient(low = "white", high = "#DE0100")+
labs(title = "Hate Crimes per 100K",
fill = "Hate Crimes per 100K") +
theme_bw()
ggplot(hate_crime_us_state) +
geom_sf(aes(fill = share_non_white, geometry = geometry))+
scale_fill_gradient(low = "white", high = "#DE0100")+
labs(title = "Share of Non White Hate Crimes",
fill = "Share of non white hate crimes") +
theme_bw()
scale = 500
ggplot(hate_crime_us_state, aes(x = share_unemployed_seasonal , y = hate_crimes_per_100k_splc)) +
geom_smooth(aes(color = "Share unemployed")) +
geom_smooth(aes(x = share_population_in_metro_areas/scale, color = "Share population in metro areas")) +
geom_smooth(aes(x = share_population_with_high_school_degree/scale, color = "Share population with high school degree")) +
geom_smooth(aes(x = share_non_citezen/scale, color = "Share non citezen")) +
geom_smooth(aes(x = share_white_poverty/scale, color = "Share white poverty")) +
geom_smooth(aes(x = share_non_white/scale, color = "Share non white")) +
geom_smooth(aes(x = share_voter_voted_trump/scale, color = "Share voters voted trump")) +
labs(title = "Citezen Type VS Hate Crime Rate per 100K",
x = "Citezen Type", y = "Hate Crime Rate per 100K") +
scale_color_manual(values = c("red", "blue", "orange", "purple", "green", "yellow", "pink"))
scale = 500
ggplot(hate_crime_us_state, aes(x = share_unemployed_seasonal , y = hate_crimes_per_100k_splc)) +
geom_smooth(aes(color = "Share unemployed")) +
geom_smooth(aes(x = share_population_in_metro_areas/scale, color = "Share population in metro areas")) +
geom_smooth(aes(x = share_population_with_high_school_degree/scale, color = "Share population with high school degree")) +
geom_smooth(aes(x = share_non_citizen/scale, color = "Share non citezen")) +
geom_smooth(aes(x = share_white_poverty/scale, color = "Share white poverty")) +
geom_smooth(aes(x = share_non_white/scale, color = "Share non white")) +
geom_smooth(aes(x = share_voter_voted_trump/scale, color = "Share voters voted trump")) +
labs(title = "Citezen Type VS Hate Crime Rate per 100K",
x = "Citezen Type", y = "Hate Crime Rate per 100K") +
scale_color_manual(values = c("red", "blue", "orange", "purple", "green", "yellow", "pink"))
scale = 500
ggplot(hate_crime_us_state, aes(x = share_unemployed_seasonal , y = hate_crimes_per_100k_splc)) +
geom_smooth(aes(color = "Share unemployed")) +
geom_smooth(aes(x = share_population_in_metro_areas/scale, color = "Share population in metro areas")) +
geom_smooth(aes(x = share_population_with_high_school_degree/scale, color = "Share population with high school degree")) +
geom_smooth(aes(x = share_non_citizen/scale, color = "Share non citezen")) +
geom_smooth(aes(x = share_white_poverty/scale, color = "Share white poverty")) +
geom_smooth(aes(x = share_non_white/scale, color = "Share non white")) +
geom_smooth(aes(x = share_voters_voted_trump/scale, color = "Share voters voted trump")) +
labs(title = "Citezen Type VS Hate Crime Rate per 100K",
x = "Citezen Type", y = "Hate Crime Rate per 100K") +
scale_color_manual(values = c("red", "blue", "orange", "purple", "green", "yellow", "pink"))
scale = 15
ggplot(hate_crime_us_state, aes(x = share_unemployed_seasonal , y = hate_crimes_per_100k_splc)) +
geom_smooth(aes(color = "Share unemployed")) +
geom_smooth(aes(x = share_population_in_metro_areas/scale, color = "Share population in metro areas")) +
geom_smooth(aes(x = share_population_with_high_school_degree/scale, color = "Share population with high school degree")) +
geom_smooth(aes(x = share_non_citizen/scale, color = "Share non citezen")) +
geom_smooth(aes(x = share_white_poverty/scale, color = "Share white poverty")) +
geom_smooth(aes(x = share_non_white/scale, color = "Share non white")) +
geom_smooth(aes(x = share_voters_voted_trump/scale, color = "Share voters voted trump")) +
labs(title = "Citezen Type VS Hate Crime Rate per 100K",
x = "Citezen Type", y = "Hate Crime Rate per 100K") +
scale_color_manual(values = c("red", "blue", "orange", "purple", "green", "yellow", "pink"))
scale = 5
ggplot(hate_crime_us_state, aes(x = share_unemployed_seasonal , y = hate_crimes_per_100k_splc)) +
geom_smooth(aes(color = "Share unemployed")) +
geom_smooth(aes(x = share_population_in_metro_areas/scale, color = "Share population in metro areas")) +
geom_smooth(aes(x = share_population_with_high_school_degree/scale, color = "Share population with high school degree")) +
geom_smooth(aes(x = share_non_citizen/scale, color = "Share non citezen")) +
geom_smooth(aes(x = share_white_poverty/scale, color = "Share white poverty")) +
geom_smooth(aes(x = share_non_white/scale, color = "Share non white")) +
geom_smooth(aes(x = share_voters_voted_trump/scale, color = "Share voters voted trump")) +
labs(title = "Citezen Type VS Hate Crime Rate per 100K",
x = "Citezen Type", y = "Hate Crime Rate per 100K") +
scale_color_manual(values = c("red", "blue", "orange", "purple", "green", "yellow", "pink"))
scale = 3
ggplot(hate_crime_us_state, aes(x = share_unemployed_seasonal , y = hate_crimes_per_100k_splc)) +
geom_smooth(aes(color = "Share unemployed")) +
geom_smooth(aes(x = share_population_in_metro_areas/scale, color = "Share population in metro areas")) +
geom_smooth(aes(x = share_population_with_high_school_degree/scale, color = "Share population with high school degree")) +
geom_smooth(aes(x = share_non_citizen/scale, color = "Share non citezen")) +
geom_smooth(aes(x = share_white_poverty/scale, color = "Share white poverty")) +
geom_smooth(aes(x = share_non_white/scale, color = "Share non white")) +
geom_smooth(aes(x = share_voters_voted_trump/scale, color = "Share voters voted trump")) +
labs(title = "Citezen Type VS Hate Crime Rate per 100K",
x = "Citezen Type", y = "Hate Crime Rate per 100K") +
scale_color_manual(values = c("red", "blue", "orange", "purple", "green", "yellow", "pink"))
scale = 15
ggplot(hate_crime_us_state, aes(x = share_unemployed_seasonal , y = hate_crimes_per_100k_splc)) +
geom_smooth(aes(color = "Share unemployed")) +
geom_smooth(aes(x = share_population_in_metro_areas/scale, color = "Share population in metro areas")) +
geom_smooth(aes(x = share_population_with_high_school_degree/scale, color = "Share population with high school degree")) +
geom_smooth(aes(x = share_non_citizen/scale, color = "Share non citezen")) +
geom_smooth(aes(x = share_white_poverty/scale, color = "Share white poverty")) +
geom_smooth(aes(x = share_non_white/scale, color = "Share non white")) +
geom_smooth(aes(x = share_voters_voted_trump/scale, color = "Share voters voted trump")) +
labs(title = "Citezen Type VS Hate Crime Rate per 100K",
x = "Citezen Type", y = "Hate Crime Rate per 100K") +
scale_color_manual(values = c("red", "blue", "orange", "purple", "green", "yellow", "pink"))
summary_hate_crimes <- hate_crime_us_state %>% summarise(unemployed_seasonal = sum(share_unemployed_seasonal), in_metro = sum(share_population_in_metro_areas), high_school = sum(share_population_with_high_school_degree), no_citizen = sum(share_non_citizen), white = sum(share_white_poverty), non_white = sum(share_non_white), trump_voters = sum(share_voters_voted_trump))
scale = 15
ggplot(hate_crime_us_state, aes(x = share_unemployed_seasonal , y = hate_crimes_per_100k_splc)) +
geom_smooth(aes(color = "Share unemployed")) +
geom_smooth(aes(x = share_population_in_metro_areas/scale, color = "Share population in metro areas")) +
geom_smooth(aes(x = share_population_with_high_school_degree/scale, color = "Share population with high school degree")) +
geom_smooth(aes(x = share_non_citizen/scale, color = "Share non citezen")) +
geom_smooth(aes(x = share_white_poverty/scale, color = "Share white poverty")) +
geom_smooth(aes(x = share_non_white/scale, color = "Share non white")) +
geom_smooth(aes(x = share_voters_voted_trump/scale, color = "Share voters voted trump")) +
labs(title = "Citezen Type VS Hate Crime Rate per 100K",
x = "Citezen Type", y = "Hate Crime Rate per 100K") +
scale_color_manual(values = c("red", "blue", "orange", "purple", "green", "yellow", "pink"))
View(summary_hate_crimes)
summary_hate_crimes <- hate_crime_us_state %>% summarise(unemployed_seasonal = sum(share_unemployed_seasonal), in_metro = sum(share_population_in_metro_areas), high_school = sum(share_population_with_high_school_degree), non_citizen = sum(share_non_citizen), white = sum(share_white_poverty), non_white = sum(share_non_white), trump_voters = sum(share_voters_voted_trump))
scale = 15
ggplot(hate_crime_us_state, aes(x = share_unemployed_seasonal , y = hate_crimes_per_100k_splc)) +
geom_smooth(aes(color = "Share unemployed")) +
geom_smooth(aes(x = share_population_in_metro_areas/scale, color = "Share population in metro areas")) +
geom_smooth(aes(x = share_population_with_high_school_degree/scale, color = "Share population with high school degree")) +
geom_smooth(aes(x = share_non_citizen/scale, color = "Share non citezen")) +
geom_smooth(aes(x = share_white_poverty/scale, color = "Share white poverty")) +
geom_smooth(aes(x = share_non_white/scale, color = "Share non white")) +
geom_smooth(aes(x = share_voters_voted_trump/scale, color = "Share voters voted trump")) +
labs(title = "Citezen Type VS Hate Crime Rate per 100K",
x = "Citezen Type", y = "Hate Crime Rate per 100K") +
scale_color_manual(values = c("red", "blue", "orange", "purple", "green", "yellow", "pink"))
#Load the required packages for part 2
library(caret)
library(dplyr)
library(readr)
library(skimr)
#Load the required packages for part 2
library(caret)
library(dplyr)
library(skimr)
#Read the dataset for part 2
bikeshare_day <- read.csv("data/bikeshare-day.csv")
View(bikeshare_day)
bikeshare_day <- bikeshare_day %>%
mutate(season=recode(season, "winter"=1,
"spring"=2,
"summer"=3,
"fall"=4,))
#Load the required packages for part 2
library(caret)
library(skimr)
#Read the dataset for part 2
bikeshare_day <- read.csv("data/bikeshare-day.csv")
bikeshare_day <- bikeshare_day %>%
mutate(season=recode(season, "winter"=1,
"spring"=2,
"summer"=3,
"fall"=4,))
bikeshare_day <- bikeshare_day %>%
mutate(season = case_when(season == 1 ~ "winter",
season == 2 ~ "spring",
season == 3 ~ "summer",
season == 4 ~ "fall"))
#Read the dataset for part 2
bikeshare_day <- read.csv("data/bikeshare-day.csv")
bikeshare_day <- bikeshare_day %>%
mutate(season = case_when(season == 1 ~ "winter",
season == 2 ~ "spring",
season == 3 ~ "summer",
season == 4 ~ "fall"))
bikeshare_day <- bikeshare_day %>%
mutate(raw_temp_actual = temp * 41,
feel_temp_actual = atemp * 50,
humidity_actual = hum * 100,
windspeed_actual = windspeed * 67)
ggplot(bikeshare_day, aes(x = season, y = cnt)) +
geom_bar(stat = "identity", fill = "green") +
labs(x = "Season", y = "Bike Rentals", title = "Bike Rentals by Season")
ggplot(bikeshare_day, aes(x = season, y = cnt)) +
geom_bar(stat = "identity", fill = "#20B2AA") +
labs(x = "Season", y = "Bike Rentals", title = "Bike Rentals by Season")
ggplot(bikeshare_day, aes(x = season, y = cnt)) +
geom_bar(stat = "identity", fill = "#20B2AA") +
scale_y_continuous(labels = scales::percent) +
labs(x = "Season", y = "Bike Rentals", title = "Bike Rentals by Season")
ggplot(bikeshare_day, aes(x = season, y = cnt/sum(cnt))) +
geom_bar(stat = "identity", fill = "#20B2AA") +
scale_y_continuous(labels = scales::percent) +
labs(x = "Season", y = "Bike Rentals", title = "Bike Rentals by Season")
# Create the training and test datasets
set.seed(100)
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(bikeshare_day$instant, p=0.8, list=FALSE)
# Step 2: Create the training  dataset
trainData <- bikeshare_day[trainRowNumbers,]
# Step 3: Create the test dataset
testData <- bikeshare_day[-trainRowNumbers,]
# Store X and Y for later use.
x = trainData[, 3:13]
y = trainData$cnt
View(x)
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(trainData, method='knnImpute')
preProcess_missingdata_model
# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnImpute
trainData <- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)
update.packages('RANN')
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(trainData, method='knnImpute')
preProcess_missingdata_model
# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnImpute
trainData <- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)
dummies_model <- dummyVars(cnt ~ ., data=trainData)
trainData_mat <- predict(dummies_model, newdata = trainData)
trainData <- data.frame(trainData_mat)
str(trainData)
View(trainData_mat)
View(testData)
View(trainData_mat)
rm(trainData_mat)
# Set the seed for reproducibility
set.seed(100)
model_bike = train(cnt ~ ., data=trainData, method = 'lr')
View(trainData)
# Create the training and test datasets
set.seed(100)
# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(bikeshare_day$instant, p=0.8, list=FALSE)
# Step 2: Create the training  dataset
trainData <- bikeshare_day[trainRowNumbers,]
# Step 3: Create the test dataset
testData <- bikeshare_day[-trainRowNumbers,]
# Store X and Y for later use.
x = trainData[, 3:13]
y = trainData$cnt
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(trainData, method='knnImpute')
preProcess_missingdata_model
# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnImpute
trainData <- predict(preProcess_missingdata_model, newdata = trainData)
anyNA(trainData)
# Set the seed for reproducibility
set.seed(100)
model_bike = train(cnt ~ ., data=trainData, method = 'lr')
# Set the seed for reproducibility
set.seed(100)
model_bike = train(cnt ~ ., data=trainData, method = 'lm')
fitted <- predict(model_bike)
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(bikeshare_day, method='knnImpute')
preProcess_missingdata_model
# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnImpute
trainData <- predict(preProcess_missingdata_model, newdata = bikeshare_day)
anyNA(trainData)
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(bikeshare_day, method='knnImpute')
preProcess_missingdata_model
# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnImpute
bikeshare_day_impute <- predict(preProcess_missingdata_model, newdata = bikeshare_day)
anyNA(trainData)
# Store X and Y for later use.
x = bikeshare_day_impute[, 3:13]
y = bikeshare_day_impute$cnt
# Store X and Y for later use.
X = bikeshare_day_impute[, 3:13]
y = bikeshare_day_impute$cnt
# Split the data into training and testing sets
set.seed(42)
train_indices <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_indices,]
y_train <- y[train_indices]
X_test <- X[-train_indices,]
y_test <- y[-train_indices]
# Create and fit the linear regression model
model_LR <- train(X_train, y_train, method = "lm")
# Make predictions on the test set
y_pred_LR <- predict(model_LR, X_test)
# Evaluate the model using mean squared error
mse_LR <- mean((y_test - y_pred_LR)^2)
print(paste("Mean Squared Error:", mse_LR))
# Calculate R-squared
r2_LR <- cor(y_pred_LR, y_test)^2
print(paste("R-squared:", r2_LR))
# Print the weights
print(model_LR$finalModel$coefficients)
# Create and train the SVM model
model_SVM <- train(X_train, y_train, method = "svmRadial")
# Create and train the SVM model
model_SVM <- train(X_train, y_train, method = "svmLinear")
# Create and fit the Random Forest regression model
model_RF <- train(
x = X_train, y = y_train,
method = "rf",
trControl = trainControl(method = "cv", number = 5),
tuneLength = 10
)
# Make predictions on the test set
y_pred_RF <- predict(model_RF, X_test)
# Evaluate the model using mean squared error
mse_RF <- mean((y_pred_RF - y_test)^2)
print(paste("Mean Squared Error:", mse_RF))
# Calculate R-squared value
r2_RF <- 1 - sum((y_test - y_pred_RF)^2) / sum((y_test - mean(y_test))^2)
print(paste("R-squared:", r2_RF))
# Create and train the SVM model
model_SVM <- train(X_train, y_train, method = "svmRadial")
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(bikeshare_day, method='knnImpute')
preProcess_missingdata_model
# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnImpute
bikeshare_day_impute <- predict(preProcess_missingdata_model, newdata = bikeshare_day)
anyNA(bikeshare_day_impute)
knitr::opts_chunk$set(echo = TRUE)
#Load the required packages
library(tidyverse)
library(sf)
#Load the required packages for part 2
library(caret)
library(skimr)
#Read the dataset for part 2
bikeshare_day <- read.csv("data/bikeshare-day.csv")
bikeshare_day <- bikeshare_day %>%
mutate(season = case_when(season == 1 ~ "winter",
season == 2 ~ "spring",
season == 3 ~ "summer",
season == 4 ~ "fall"))
bikeshare_day <- bikeshare_day %>%
mutate(raw_temp_actual = temp * 41,
feel_temp_actual = atemp * 50,
humidity_actual = hum * 100,
windspeed_actual = windspeed * 67)
ggplot(bikeshare_day, aes(x = season, y = cnt/sum(cnt))) +
geom_bar(stat = "identity", fill = "#20B2AA") +
scale_y_continuous(labels = scales::percent) +
labs(x = "Season", y = "Bike Rentals", title = "Bike Rentals by Season")
# Create the knn imputation model on the training data
preProcess_missingdata_model <- preProcess(bikeshare_day, method='knnImpute')
preProcess_missingdata_model
# Use the imputation model to predict the values of missing data points
library(RANN)  # required for knnImpute
bikeshare_day_impute <- predict(preProcess_missingdata_model, newdata = bikeshare_day)
anyNA(bikeshare_day_impute)
View(bikeshare_day_impute)
View(bikeshare_day)
